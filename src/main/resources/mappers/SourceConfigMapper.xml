<?xml version="1.0" encoding="UTF-8" ?>
<!--
  ~    Licensed under the Apache License, Version 2.0 (the "License");
  ~    you may not use this file except in compliance with the License.
  ~    You may obtain a copy of the License at
  ~
  ~        http://www.apache.org/licenses/LICENSE-2.0
  ~
  ~    Unless required by applicable law or agreed to in writing, software
  ~    distributed under the License is distributed on an "AS IS" BASIS,
  ~    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  ~    See the License for the specific language governing permissions and
  ~    limitations under the License.
  -->

<!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd" >
<mapper namespace="com.wgzhao.addax.admin.mapper.SourceConfigMapper" >
  <resultMap id="BaseResultMap" type="com.wgzhao.addax.admin.pojo.SourceConfig" >
    <id column="id" property="id" jdbcType="VARCHAR" />
    <result column="name" property="name" jdbcType="VARCHAR" />
    <result column="user" property="user" jdbcType="VARCHAR" />
    <result column="pass" property="pass" jdbcType="VARCHAR" />
    <result column="dsn" property="dsn" jdbcType="VARCHAR" />
    <result column="dtype" property="dtype" jdbcType="INTEGER" />
    <result column="dstatus" property="dstatus" jdbcType="INTEGER" />
    <result column="path" property="path" jdbcType="VARCHAR" />
    <result column="defaultFS" property="defaultFS" jdbcType="VARCHAR" />
    <result column="have_kerberos" property="haveKerberos" jdbcType="INTEGER" />
    <result column="kerberos_keytab_file_path" property="kerberosKeytabFilePath" jdbcType="VARCHAR" />
    <result column="kerberos_principal" property="kerberosPrincipal" jdbcType="VARCHAR" />
    <result column="hadoop_config" property="hadoopConfig" jdbcType="VARCHAR" />
    <result column="hive_user_name" property="hiveUserName" jdbcType="VARCHAR" />
    <result column="hive_pass" property="hivePass" jdbcType="VARCHAR" />
    <result column="hive_connect_str" property="hiveConnectStr" jdbcType="VARCHAR" />
    <result column="is_enable_ha" property="isEnableHa" jdbcType="INTEGER" />
    <result column="name_services" property="nameServices" jdbcType="VARCHAR" />
    <result column="name_nodes" property="nameNodes" jdbcType="VARCHAR" />
    <result column="name_node_rpc" property="nameNodeRpc" jdbcType="VARCHAR" />
    <result column="ctime" property="ctime" jdbcType="TIMESTAMP" />
    <result column="mtime" property="mtime" jdbcType="TIMESTAMP" />
  </resultMap>
  <sql id="Base_Column_List" >
    id, name, user, pass, dsn, dtype, dstatus, path, defaultFS, have_kerberos, kerberos_keytab_file_path, 
    kerberos_principal, hadoop_config, hive_user_name, hive_pass, hive_connect_str, is_enable_ha, 
    name_services, name_nodes, name_node_rpc, ctime, mtime
  </sql>
  <select id="selectByPrimaryKey" resultMap="BaseResultMap" parameterType="java.lang.String" >
    select 
    <include refid="Base_Column_List" />
    from t_source_config
    where id = #{id,jdbcType=VARCHAR}
  </select>
  <delete id="deleteByPrimaryKey" parameterType="java.lang.String" >
    delete from t_source_config
    where id = #{id,jdbcType=VARCHAR}
  </delete>
  <insert id="insert" parameterType="com.wgzhao.addax.admin.pojo.SourceConfig" >
    insert into t_source_config (id, name, user, 
      pass, dsn, dtype, dstatus, 
      path, defaultFS, have_kerberos, 
      kerberos_keytab_file_path, kerberos_principal, 
      hadoop_config, hive_user_name, hive_pass, 
      hive_connect_str, is_enable_ha, name_services, 
      name_nodes, name_node_rpc, ctime, 
      mtime)
    values (#{id,jdbcType=VARCHAR}, #{name,jdbcType=VARCHAR}, #{user,jdbcType=VARCHAR}, 
      #{pass,jdbcType=VARCHAR}, #{dsn,jdbcType=VARCHAR}, #{dtype,jdbcType=INTEGER}, #{dstatus,jdbcType=INTEGER}, 
      #{path,jdbcType=VARCHAR}, #{defaultFS,jdbcType=VARCHAR}, #{haveKerberos,jdbcType=INTEGER},
      #{kerberosKeytabFilePath,jdbcType=VARCHAR}, #{kerberosPrincipal,jdbcType=VARCHAR}, 
      #{hadoopConfig,jdbcType=VARCHAR}, #{hiveUserName,jdbcType=VARCHAR}, #{hivePass,jdbcType=VARCHAR}, 
      #{hiveConnectStr,jdbcType=VARCHAR}, #{isEnableHa,jdbcType=INTEGER}, #{nameServices,jdbcType=VARCHAR}, 
      #{nameNodes,jdbcType=VARCHAR}, #{nameNodeRpc,jdbcType=VARCHAR}, #{ctime,jdbcType=TIMESTAMP}, 
      #{mtime,jdbcType=TIMESTAMP})
  </insert>
  <insert id="insertSelective" parameterType="com.wgzhao.addax.admin.pojo.SourceConfig" >
    insert into t_source_config
    <trim prefix="(" suffix=")" suffixOverrides="," >
      <if test="id != null" >
        id,
      </if>
      <if test="name != null" >
        name,
      </if>
      <if test="user != null" >
        user,
      </if>
      <if test="pass != null" >
        pass,
      </if>
      <if test="dsn != null" >
        dsn,
      </if>
      <if test="dtype != null" >
        dtype,
      </if>
      <if test="dstatus != null" >
        dstatus,
      </if>
      <if test="path != null" >
        path,
      </if>
      <if test="defaultFS != null" >
        defaultFS,
      </if>
      <if test="haveKerberos != null" >
        have_kerberos,
      </if>
      <if test="kerberosKeytabFilePath != null" >
        kerberos_keytab_file_path,
      </if>
      <if test="kerberosPrincipal != null" >
        kerberos_principal,
      </if>
      <if test="hadoopConfig != null" >
        hadoop_config,
      </if>
      <if test="hiveUserName != null" >
        hive_user_name,
      </if>
      <if test="hivePass != null" >
        hive_pass,
      </if>
      <if test="hiveConnectStr != null" >
        hive_connect_str,
      </if>
      <if test="isEnableHa != null" >
        is_enable_ha,
      </if>
      <if test="nameServices != null" >
        name_services,
      </if>
      <if test="nameNodes != null" >
        name_nodes,
      </if>
      <if test="nameNodeRpc != null" >
        name_node_rpc,
      </if>
      <if test="ctime != null" >
        ctime,
      </if>
      <if test="mtime != null" >
        mtime,
      </if>
    </trim>
    <trim prefix="values (" suffix=")" suffixOverrides="," >
      <if test="id != null" >
        #{id,jdbcType=VARCHAR},
      </if>
      <if test="name != null" >
        #{name,jdbcType=VARCHAR},
      </if>
      <if test="user != null" >
        #{user,jdbcType=VARCHAR},
      </if>
      <if test="pass != null" >
        #{pass,jdbcType=VARCHAR},
      </if>
      <if test="dsn != null" >
        #{dsn,jdbcType=VARCHAR},
      </if>
      <if test="dtype != null" >
        #{dtype,jdbcType=INTEGER},
      </if>
      <if test="dstatus != null" >
        #{dstatus,jdbcType=INTEGER},
      </if>
      <if test="path != null" >
        #{path,jdbcType=VARCHAR},
      </if>
      <if test="defaultFS != null" >
        #{defaultfs,jdbcType=VARCHAR},
      </if>
      <if test="haveKerberos != null" >
        #{haveKerberos,jdbcType=INTEGER},
      </if>
      <if test="kerberosKeytabFilePath != null" >
        #{kerberosKeytabFilePath,jdbcType=VARCHAR},
      </if>
      <if test="kerberosPrincipal != null" >
        #{kerberosPrincipal,jdbcType=VARCHAR},
      </if>
      <if test="hadoopConfig != null" >
        #{hadoopConfig,jdbcType=VARCHAR},
      </if>
      <if test="hiveUserName != null" >
        #{hiveUserName,jdbcType=VARCHAR},
      </if>
      <if test="hivePass != null" >
        #{hivePass,jdbcType=VARCHAR},
      </if>
      <if test="hiveConnectStr != null" >
        #{hiveConnectStr,jdbcType=VARCHAR},
      </if>
      <if test="isEnableHa != null" >
        #{isEnableHa,jdbcType=INTEGER},
      </if>
      <if test="nameServices != null" >
        #{nameServices,jdbcType=VARCHAR},
      </if>
      <if test="nameNodes != null" >
        #{nameNodes,jdbcType=VARCHAR},
      </if>
      <if test="nameNodeRpc != null" >
        #{nameNodeRpc,jdbcType=VARCHAR},
      </if>
      <if test="ctime != null" >
        #{ctime,jdbcType=TIMESTAMP},
      </if>
      <if test="mtime != null" >
        #{mtime,jdbcType=TIMESTAMP},
      </if>
    </trim>
  </insert>
  <update id="updateByPrimaryKeySelective" parameterType="com.wgzhao.addax.admin.pojo.SourceConfig" >
    update t_source_config
    <set >
      <if test="name != null" >
        name = #{name,jdbcType=VARCHAR},
      </if>
      <if test="user != null" >
        user = #{user,jdbcType=VARCHAR},
      </if>
      <if test="pass != null" >
        pass = #{pass,jdbcType=VARCHAR},
      </if>
      <if test="dsn != null" >
        dsn = #{dsn,jdbcType=VARCHAR},
      </if>
      <if test="dtype != null" >
        dtype = #{dtype,jdbcType=INTEGER},
      </if>
      <if test="dstatus != null" >
        dstatus = #{dstatus,jdbcType=INTEGER},
      </if>
      <if test="path != null" >
        path = #{path,jdbcType=VARCHAR},
      </if>
      <if test="defaultfs != null" >
        defaultFS = #{defaultfs,jdbcType=VARCHAR},
      </if>
      <if test="haveKerberos != null" >
        have_kerberos = #{haveKerberos,jdbcType=INTEGER},
      </if>
      <if test="kerberosKeytabFilePath != null" >
        kerberos_keytab_file_path = #{kerberosKeytabFilePath,jdbcType=VARCHAR},
      </if>
      <if test="kerberosPrincipal != null" >
        kerberos_principal = #{kerberosPrincipal,jdbcType=VARCHAR},
      </if>
      <if test="hadoopConfig != null" >
        hadoop_config = #{hadoopConfig,jdbcType=VARCHAR},
      </if>
      <if test="hiveUserName != null" >
        hive_user_name = #{hiveUserName,jdbcType=VARCHAR},
      </if>
      <if test="hivePass != null" >
        hive_pass = #{hivePass,jdbcType=VARCHAR},
      </if>
      <if test="hiveConnectStr != null" >
        hive_connect_str = #{hiveConnectStr,jdbcType=VARCHAR},
      </if>
      <if test="isEnableHa != null" >
        is_enable_ha = #{isEnableHa,jdbcType=INTEGER},
      </if>
      <if test="nameServices != null" >
        name_services = #{nameServices,jdbcType=VARCHAR},
      </if>
      <if test="nameNodes != null" >
        name_nodes = #{nameNodes,jdbcType=VARCHAR},
      </if>
      <if test="nameNodeRpc != null" >
        name_node_rpc = #{nameNodeRpc,jdbcType=VARCHAR},
      </if>
      <if test="ctime != null" >
        ctime = #{ctime,jdbcType=TIMESTAMP},
      </if>
      <if test="mtime != null" >
        mtime = #{mtime,jdbcType=TIMESTAMP},
      </if>
    </set>
    where id = #{id,jdbcType=VARCHAR}
  </update>
  <update id="updateByPrimaryKey" parameterType="com.wgzhao.addax.admin.pojo.SourceConfig" >
    update t_source_config
    set name = #{name,jdbcType=VARCHAR},
      user = #{user,jdbcType=VARCHAR},
      pass = #{pass,jdbcType=VARCHAR},
      dsn = #{dsn,jdbcType=VARCHAR},
      dtype = #{dtype,jdbcType=INTEGER},
      dstatus = #{dstatus,jdbcType=INTEGER},
      path = #{path,jdbcType=VARCHAR},
      defaultFS = #{defaultfs,jdbcType=VARCHAR},
      have_kerberos = #{haveKerberos,jdbcType=INTEGER},
      kerberos_keytab_file_path = #{kerberosKeytabFilePath,jdbcType=VARCHAR},
      kerberos_principal = #{kerberosPrincipal,jdbcType=VARCHAR},
      hadoop_config = #{hadoopConfig,jdbcType=VARCHAR},
      hive_user_name = #{hiveUserName,jdbcType=VARCHAR},
      hive_pass = #{hivePass,jdbcType=VARCHAR},
      hive_connect_str = #{hiveConnectStr,jdbcType=VARCHAR},
      is_enable_ha = #{isEnableHa,jdbcType=INTEGER},
      name_services = #{nameServices,jdbcType=VARCHAR},
      name_nodes = #{nameNodes,jdbcType=VARCHAR},
      name_node_rpc = #{nameNodeRpc,jdbcType=VARCHAR},
      ctime = #{ctime,jdbcType=TIMESTAMP},
      mtime = #{mtime,jdbcType=TIMESTAMP}
    where id = #{id,jdbcType=VARCHAR}
  </update>
</mapper>